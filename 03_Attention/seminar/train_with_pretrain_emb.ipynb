{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce95970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from configs import config\n",
    "from transformer import EncoderDecoder\n",
    "from preprocessing_emb import preprocessing\n",
    "from metrics import LabelSmoothingLoss\n",
    "from optimizer import NoamOpt\n",
    "from transformer import fit\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c705416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wandb login f40bc28fcdb2758937b8be9acbc2bbc7b6509b6e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03422909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to verify login in offline mode.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x26255ca4890>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "# Запуск проекта и конфигурации\n",
    "wandb.init(project=\"transformer-summarizer\", config={\n",
    "    \"epochs\": config['epochs'],\n",
    "    \"batch_size\": config['b_size_train'],\n",
    "    \"learning_rate\": config['learning_rate'],\n",
    "    \"model\": \"EncoderDecoder\",\n",
    "    \"d_model\": config['d_model'],\n",
    "    \"n_heads\": config['n_heads'],\n",
    "})\n",
    "\n",
    "# !wandb sync \"D:/05_Attention/05_Attention/seminar/wandb/offline-run-20250526_162725-2622dbq9\"\n",
    "# !wandb sync \"D:/05_Attention/05_Attention/seminar/wandb/offline-run-*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f1945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vladlen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"news.csv\")\n",
    "train_iter, test_iter, tokenizer, d_model = preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4c72258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n"
     ]
    }
   ],
   "source": [
    "print(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a42934c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201db839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.d_model = 312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n"
     ]
    }
   ],
   "source": [
    "model = EncoderDecoder(word_field=None, d_model=d_model,tokenizer=tokenizer)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dcdf441",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = tokenizer.pad_token\n",
    "vocab_size = len(tokenizer)\n",
    "criterion = LabelSmoothingLoss(vocab_size,  padding_idx=pad_idx).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6773153b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a64fa0ae4704d1f9b15ff0cb83f8673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3946 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'preprocessing_emb.collate_fn.<locals>.Batch'>\n",
      "Batch size (number of examples): source=16, target=16\n",
      "source_embeddings shape: torch.Size([16, 174, 312])\n",
      "source_mask shape: torch.Size([16, 174])\n",
      "target_embeddings shape: torch.Size([16, 16, 312])\n",
      "target_mask shape: torch.Size([16, 16])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m NoamOpt(model)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\05_Attention\\05_Attention\\seminar\\transformer.py:166\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, criterion, optimizer, train_iter, epochs_count, val_iter)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs_count):\n\u001b[0;32m    165\u001b[0m     name_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, epochs_count)\n\u001b[1;32m--> 166\u001b[0m     train_loss, global_step \u001b[38;5;241m=\u001b[39m \u001b[43mdo_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_prefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrain:\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m val_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m         val_loss, _ \u001b[38;5;241m=\u001b[39m do_epoch(model, criterion, val_iter, \u001b[38;5;28;01mNone\u001b[39;00m, name_prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  Val:\u001b[39m\u001b[38;5;124m'\u001b[39m, global_step\u001b[38;5;241m=\u001b[39mglobal_step)\n",
      "File \u001b[1;32md:\\05_Attention\\05_Attention\\seminar\\transformer.py:102\u001b[0m, in \u001b[0;36mdo_epoch\u001b[1;34m(model, criterion, data_iter, optimizer, name, global_step)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# if model.embedding is not None:\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m#     source_inputs, target_inputs, source_mask, target_mask = convert_batch(batch)\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[0;32m    100\u001b[0m source_inputs, target_inputs, source_mask, target_mask \u001b[38;5;241m=\u001b[39m convert_batch_with_pretrain_emb(batch) \u001b[38;5;66;03m# check\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m logits \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(source_inputs, target_inputs[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], source_mask, \u001b[43mtarget_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;66;03m# потом убрать\u001b[39;00m\n\u001b[0;32m    103\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m    104\u001b[0m target \u001b[38;5;241m=\u001b[39m target_inputs[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# истинные индексы токенов\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "optimizer = NoamOpt(model)\n",
    "fit(model, criterion, optimizer, train_iter, epochs_count=10, val_iter=test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244dae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.d_model = 312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n"
     ]
    }
   ],
   "source": [
    "model = EncoderDecoder(word_field=None, d_model=d_model,tokenizer=tokenizer)\n",
    "model = model.to(DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
